\documentclass[thesis.tex]{subfiles}
\begin{document}

\chapter{Prerequisites}\label{chap:basics}
The following sections explain some of the underlying principles that are required to understand the later chapters in this thesis.
Readers that are familiar with the basic concepts of photorealistic and realtime rendering may skip parts of this chapter.

% What belongs here:
% - Mathematics
% - Things that I would expect the reader to know if this would be a paper
% - What constraints are just there
% What does not belong here:
% - References to work that is directly related to the topic

\section{Theoretical Foundation}
This section explains some of the fundamentals of physically based rendering.
We will only discuss a few basics which are helpful for a good understanding of this thesis.
For more detailed explanations the reader is referred to the book \emph{Physically Based Rendering, From Theory to Implementation} by Pharr and Humphreys \cite{bib:pbrt}.

\subsection{Physical Foundation}
Light is generally an electromagnetic wave which originates at a light source and is bounced of or absorbed by the surfaces it hits.
As such, there are several complicated physical properties like diffraction,interference and quantization effects (due to the particle properties of electromagnetic waves) which are usually ignored for rendering, as they play most of the time a minor role.
Each light particle (= photon) has a certain wavelength which is responsible for the perceived color.
We are only interested in the visible part of the spectrum which ranges from about $380nm$ to $780nm$.
The number of photons registered by the eye defines the brightness.
\\
As the human retina has only three receptors, each with a given range of wavelength-support, it is usually sufficient to perform all calculations using only the three basic color stimuli red, green and blue \cite{bib:colorscience}.
However, as recently pointed out by Meng et al. \cite{bib:spectrumrendering} there are several problems that might lead to color shifts and violation of energy conservation. \todo{recheck when I heared that talk (upcoming EGSR)}

\subsection{Radiometric Quantities}
There are several basic quantities that describe the transport and perception of light.
\\
\emph{Radiant flux} $\phi$ describes the energetic output of a light source.
It measures how much energy a light source emits over time and is thus given in watts.
\\
Irradiance $E$ determines how much light (flux $phi$) per area $A$ a surface receives:
\begin{equation}
E = \frac{\mathrm{d}\phi}{\mathrm{d}A}
\end{equation}
The opposite, how much light per area is leaving a surface, is also called radiant exitance of radiosity.
However, as in many other works, we will use the term for both incident and exitant light.

The remaining two quantities depends on a \emph{solid angle}, the 3D equivalent of a 2D arc length.
The solid angle subtended by an object is computed by the projected area on the unit sphere in a given point.
Solid angles are measured in steradians $sr$.
A solid angle representing the entire unit sphere, has $4\pi\,sr$.
As common, we use the symbol $\omega$ both for the solid angle itself and the normalized directions of a differential solid angles when integrating over (a part of) a sphere.
For example, an integration of a direction dependent function $f(\mathbf{x})$ over all directions in a hemisphere is expressed as:
\begin{equation}
\int_{2\pi\,sr} f(\omega) \, \mathrm{d}\omega
\end{equation} 
$\mathrm{d}\omega$ denotes the differential steradian, $\omega$ alone a single direction on the unit hemisphere.

\emph{Intensity} $I$ gives how much flux $\phi$ per solid angle $\omega$ is emitted in a certain direction:
\begin{equation}
I = \frac{\mathrm{d}\phi}{\mathrm{d}\omega}
\end{equation}
It is especially useful to describe in which direction light sources emit more or less light.
\\
The last and most important quantity is \emph{radiance} $L$ since it is the which is "visible" as it corresponds to the seen brightness.
It is defined as emitted flux $\phi$ per solid angle $\omega$ per projected emitter area $A^\perp$ in respect to a certain detector.
\begin{equation}
L = \frac{\mathrm{d}\phi}{\mathrm{d}\omega \cdot \mathrm{d}A^\perp }
\end{equation}
The projected ("seen") differential area $\mathrm{d}A^\perp$ is depended of the angle $\theta$ between emitter surface and detector direction:
\begin{equation}
\mathrm{d}A^\perp = \mathrm{d}A \cdot \cos\theta
\end{equation}

\todo{figures for flux, I, E, L and solid angle}
%$\phi$ & \textbf{Radiant Flux}, light power\\
%$I$ & \textbf{Radiant Intensity}, flux density per solid angle\\
%$E$ & \textbf{Irradiance}, flux density per area\\
%$L$ & \textbf{Radiance}, flux density per area per solid angle\\

\subsection{Rendering Equation}
The well-known rendering equation by Kajiya \cite{bib:renderingequation} is a general description of the radiance in a given point $x$ in a direction $\omega_o$:
\begin{equation}
L_o(x, \omega_o) = L_e(x, \omega_o) + \int_{2\pi\,sr} f(x, \omega_i, \omega_o) \cdot L_i(x, \omega_i) \cdot \cos\theta_i \, \mathrm{d}\omega_i
\end{equation}
Where $L_e$ is the self-emission and $L_i$ the incoming radiance for a given direction.
$f$ denotes the \emph{bidirectional reflection distribution function} (BRDF) that describes how the surface reflects light.
It will be examined more closely in the next section.
The integral sums for all directions $\omega_i$ on the hemisphere, how much light is reflected to a observer in the direction $\omega_o$.
Note that the evaluation of a single $L_i$ again requires the evaluation of the entire equation.
This means that in theory the radiance at any point in any direction depends on all other points.
Approaches that try to solve or approximate this recursive property of the rendering equation are thus performing \emph{global illumination}, as opposed to \emph{local illumination} where $L_i$ only includes directly visible light sources.

One of the easiest ways of solving the rendering equation is path tracing which was presented alongside the equation.
It solves the integral via a Monte Carlo integration:
For each radiance sample multiple rays are shot into the scene.
At each intersection the emissivity of the surface is evaluated. 
The ray is reflected accordingly to the local material, using the BRDF as probability density.

There are several phenomenons which are ignored by this basic form of the rendering equation.
For example it is assumed that light travels through vacuum, i.e. no scattering or absorption within participating media occurs.

\subsection{Bidirectional Reflectance Distribution Function}
Introduce theory and Blinn-Phong
separation of Diffuse and Specular

%$\rho$ & \textbf{Reflectance}, ratio between incoming and outgoing flux\\

\subsection{Common Types of Light Sources and Basic Relations}

\section{Realtime Rendering}
Super awesome book about EVERYTHING! \cite{bib:RealtimeRenderingBook} (Tomas Akenine-M\"{o}ller and Eric Haines and Natty Hoffman).

\subsection{Local Illumination}


\subsection{Shadow Mapping}
Basics!

\subsection{Deferred Rendering}


\subsection{Deferred Rendering}
Basics only!

\section{Modern GPU Pipeline and Capabilities}
OpenGL 4.5 pipeline picture?
A lot of information about shaders and compute.

\section{Spherical Harmonics}\label{sec:pre:sh}
Spherical Harmonics (SH) are a set of orthonormal basis functions, analogous to the Fourier transform's basis functions, but defined on the surface of a sphere.
They are often used in computer graphics to approximate spherical functions like visibility, lighting or reflectance. Similarly, they will later be used in \autoref{sec:impl:diffuse} to describe the total irradiance for a given normal.

More detailed explanations can be found for example in \cite{bib:grittysph, bib:stupidsph} on which this summary is based.

\subsection{Definition} \label{chap:sh:def}
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{sh}
	\caption{\cite{bib:grittysph} The first three SH bands plotted as unsigned spherical functions by distance from the origin unit sphere. Green are positive values, red are negative ones.}
	\label{fig:shvisualization}
\end{figure}
\todo{Better image quality!}
The SH functions in general are defined on imaginary numbers, but for use in computer graphics usually only real-number Spherical Harmonics are relevant.

$y^m_l(\theta, \varphi)$ represents a Spherical Harmonic function.
The angles $\theta$ and $\varphi$ give a point on the unit hemisphere.
To convert from spherical to cartesian coordinates we use the following conversion:
\begin{equation} \label{equ:postoangle}
(\sin\theta\cos\varphi, \sin\theta\sin\varphi, \cos\theta) \rightarrow (x,y,z)
\end{equation}
The index $l$ represents the Spherical Harmonic \emph{band}.
Each band consists of polynomials of the degree $l$ (zero is a constant function, 1 is linear, etc.).
There are $2l+1$ functions for a given band.
Accordingly, the higher the band index $l$, the higher is the frequency of the information that is encoded in this band.
\autoref{fig:shvisualization} visualizes the first three bands.

$y^m_l(\theta, \varphi)$ is defined as:
\begin{equation}
	\begin{alignedat}{2}
		y^m_l(\theta, \varphi) &= \begin{cases}
		\sqrt{2}K^m_l \cos(m\varphi) P^m_l(\cos\theta) & m>0\\
		\sqrt{2}K^m_l \sin(-m\varphi) P^{-m}_l(\cos\theta) & m<0\\
		K^0_l P^0_l(\cos\theta) & m=0.\end{cases}
	\end{alignedat}
\end{equation}
Where $P^m_l(x)$ are the associated \emph{Legendre} polynomials and $K^m_l$ are normalization constants defined as:
\begin{equation}
	K^m_l = \sqrt{\frac{(2l+1)(l-|m|)!}{4\pi(l+|m|)!}}
\end{equation}

The associated Legendre polynomials are recursively defined as following:
\begin{equation}
	\begin{alignedat}{2}
		P^0_0(x) &= 1\\
		P^m_m(x) &= (1-2m)P^{m-1}_{m-1}\\
		P^m_{m+1}(x) &= x(2m+1)P^m_m\\	
		P^m_l(x) &= \frac{x(2l-1)P^m_{l-1}(x)-(l+m-1)P^m_{l-2}}{l-m}
	\end{alignedat}
\end{equation}


\subsection{Projection and Reconstruction} \label{chap:shprojectrecon}
Each spherical function $f(\theta, \varphi)$ can be represented with an infinite series of SH functions, each weighted by a SH coefficient.
To calculate a SH coefficient for a given band of a spherical function $f$, the product of $f$ and the SH function $y$ needs to be integrated:
\begin{equation} \label{eq:shprojection}
	c^m_l=\int\limits_{2\pi sr} f(\omega)y^m_l(\omega)\, \mathrm{d}\omega
\end{equation}
\todo{$2\pi sr$ integral must be introduced earlier}

By truncating the SH representation to $n$ bands, a function $f$ can be approximated:
\begin{equation}
	\widetilde{f}(s) = \sum_{l=0}^{n-l}\sum_{m=-l}^l c_l^m y_l^m(s)
\end{equation}

\subsection{Rotation and Zonal Harmonics} \label{sec:pre:zonalharmonics}
Spherical Harmonics are rotationally invariant:
If a function $g$ is a copy rotated by $R$ named $f$, then for the corresponding SH projections $\widetilde{g}$ and $\widetilde{f}$ it is true that:
\begin{equation}
	\widetilde{g}(s) = \widetilde{f}(R(s))
\end{equation}
This means that it is possible to rotate a function in its SH representation, without losing precision (other than rounding errors).

Later on this property will be very useful combined with \emph{Zonal Harmonics}.
Zonal Harmonics are SH projections of functions that have rotational symmetry around an axis.
If the axis is Z (in respect to \autoref{equ:postoangle}), then only the $c^m_0$ coefficients of the SH projection will be non-zero.\\
Rotation of such Zonal Harmonics $z_l$ to a new direction $d$ is generally much easier than arbitrary SH.
The resulting, rotated Spherical Harmonics coefficients are obtained as:
\begin{equation} \label{eq:zonalrotate}
	c_l^m = \sqrt{\frac{4\pi}{2l+1}} z_l y_l^m(d)
\end{equation}
\todo{Image of Zonal Harmonics}

\subfilebib % Makes bibliography available when compiling as subfile
\end{document}